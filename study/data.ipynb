{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B3情報科学演習：時系列データ分析（前編）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### はじめに"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に研究などのプロジェクトに取り組む際には, \"長期的な見通し\" を持つことが重要である  \n",
    "例えば, 以下のような点をある程度の粒度で抑えておくことで, 矛盾を防ぐことができる  \n",
    "- 概要・目的  \n",
    "- 実施条件  \n",
    "- 実施手法  \n",
    "- 評価方法  \n",
    "\n",
    "※特に共同研究や規模の大きなプロジェクトなど, 複数人で進めていく場合に効果を実感する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例に倣って, 前提条件を設定する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前提条件"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 概要・目的   \n",
    "　― 気温, 風速, 風向などの様々な要素(説明変数)から, 日射量(目的変数)を推定する学習モデルを作成する\n",
    "- 実施条件  \n",
    "　― 過去, 現在の説明変数から, 現在の目的変数を推定する  \n",
    "- 実施手法  \n",
    "　― 学習器には, RandomForestとLSTMを試す  \n",
    "　― 他の学習器は別途各自調べて, 実装してみるのもあり  \n",
    "- モデルの評価方法  \n",
    "　― 決定係数（R^2）と 二乗平均平方根誤差（RMSE）  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは, これから実際に\"データ処理\"のコードを書いていく  \n",
    "流れとしては,  \n",
    "「ライブラリのインポート」  \n",
    "→「データ読み込み」  \n",
    "→「データクレンジング」  \n",
    "→「データ前処理」  \n",
    "→「特徴量エンジニアリング(FE)」  \n",
    "→「データ探索分析(EDA)」  \n",
    "→「データ保存」  \n",
    "という流れで進める"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用するライブラリを最初にインポートする  \n",
    "最初にインポートするのは後から特定のセルを実行する際に，それより前のセルをすべて実行する必要をなくすためである"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "from pytz import timezone\n",
    "from tqdm import tqdm\n",
    "from tsfresh.feature_extraction import extract_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読み込み"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はExcelファイルで渡されたため、pandasのread_excel()で読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIX時間</th>\n",
       "      <th>日付</th>\n",
       "      <th>現地時間</th>\n",
       "      <th>日射量[w/㎡]</th>\n",
       "      <th>華氏[ºF]</th>\n",
       "      <th>気圧[Hg]</th>\n",
       "      <th>湿度[%]</th>\n",
       "      <th>風向[度]</th>\n",
       "      <th>風速[mph]</th>\n",
       "      <th>日の出時刻</th>\n",
       "      <th>日の入り時刻</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1472724008</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>00:00:08</td>\n",
       "      <td>2.58</td>\n",
       "      <td>51</td>\n",
       "      <td>30.43</td>\n",
       "      <td>103</td>\n",
       "      <td>77.27</td>\n",
       "      <td>11.25</td>\n",
       "      <td>06:07:00</td>\n",
       "      <td>18:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1472724310</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>00:05:10</td>\n",
       "      <td>2.83</td>\n",
       "      <td>51</td>\n",
       "      <td>30.43</td>\n",
       "      <td>103</td>\n",
       "      <td>153.44</td>\n",
       "      <td>9.00</td>\n",
       "      <td>06:07:00</td>\n",
       "      <td>18:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1472725206</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>00:20:06</td>\n",
       "      <td>2.16</td>\n",
       "      <td>51</td>\n",
       "      <td>30.43</td>\n",
       "      <td>103</td>\n",
       "      <td>142.04</td>\n",
       "      <td>7.87</td>\n",
       "      <td>06:07:00</td>\n",
       "      <td>18:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1472725505</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>00:25:05</td>\n",
       "      <td>2.21</td>\n",
       "      <td>51</td>\n",
       "      <td>30.43</td>\n",
       "      <td>103</td>\n",
       "      <td>144.12</td>\n",
       "      <td>18.00</td>\n",
       "      <td>06:07:00</td>\n",
       "      <td>18:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1472725809</td>\n",
       "      <td>9/1/2016</td>\n",
       "      <td>00:30:09</td>\n",
       "      <td>2.25</td>\n",
       "      <td>51</td>\n",
       "      <td>30.43</td>\n",
       "      <td>103</td>\n",
       "      <td>67.42</td>\n",
       "      <td>11.25</td>\n",
       "      <td>06:07:00</td>\n",
       "      <td>18:38:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UNIX時間        日付      現地時間  日射量[w/㎡]  華氏[ºF]  気圧[Hg]  湿度[%]   風向[度]  \\\n",
       "0  1472724008  9/1/2016  00:00:08      2.58      51   30.43    103   77.27   \n",
       "1  1472724310  9/1/2016  00:05:10      2.83      51   30.43    103  153.44   \n",
       "2  1472725206  9/1/2016  00:20:06      2.16      51   30.43    103  142.04   \n",
       "3  1472725505  9/1/2016  00:25:05      2.21      51   30.43    103  144.12   \n",
       "4  1472725809  9/1/2016  00:30:09      2.25      51   30.43    103   67.42   \n",
       "\n",
       "   風速[mph]     日の出時刻    日の入り時刻  \n",
       "0    11.25  06:07:00  18:38:00  \n",
       "1     9.00  06:07:00  18:38:00  \n",
       "2     7.87  06:07:00  18:38:00  \n",
       "3    18.00  06:07:00  18:38:00  \n",
       "4    11.25  06:07:00  18:38:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_data = pd.read_excel('./data/trainval_data.xlsx')\n",
    "org_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "情報系の人はcsvやtsv形式を好む人が多いが、一般的にはアプリケーションで扱いやすいExcelファイルで渡されることが多い  \n",
    "本当に酷い場合はpdf形式で渡されることがあると就活時のインターン先の方から聞いたことがあるが，仕方がないこと  \n",
    "極力，対処法を自分で見つけて，本当に無理なら他のデータ形式で頂けないかデータ提供者に相談する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データクレンジング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ提供型の共同研究では少し使いづらいデータ形式で渡されることがあるので，最初に自分が使いやすい形式に変換を行なう  \n",
    "Excelソフトを使って手動で編集しても良いが，データ量が多いと処理に時間がかかったり，間違いがあったときに再度始めから行うのが面倒（マクロを使うのもあり）  \n",
    "データ処理もスクリプト化して追加データにも対応可能にした方が良い"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず, 日本語でも使用できるが面倒な時があるため英語に変換する  \n",
    "長すぎず分かりやすい英数字表記にする  \n",
    "DataFrame.columnsに直接代入しても良いが、分かりやすくrename()を使用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_to_en = {\n",
    "    'UNIX時間':'UNIX_Time',\n",
    "    '日付':'Date',\n",
    "    '現地時間':'Time',\n",
    "    '日射量[w/㎡]':'Radiation',\n",
    "    '華氏[ºF]':'Temprature',\n",
    "    '気圧[Hg]':'Pressure',\n",
    "    '湿度[%]':'Humidity',\n",
    "    '風向[度]':'Wind_Direction',\n",
    "    '風速[mph]':'Wind_Speed',\n",
    "    '日の出時刻':'SunRise_Time',\n",
    "    '日の入り時刻':'SunSet_Time'\n",
    "}\n",
    "trainval_data = org_data.copy()\n",
    "trainval_data.rename(columns=jp_to_en, inplace=True)\n",
    "trainval_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "センサデータを扱う際は基本的に連続値を使うことが多いが，まれに離散値が混じる場合も十分あり得る  \n",
    "連続値は特に考えずそのまま使ってよいが，離散値は何かしら前処理が必要になることが多い  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ型の確認\n",
    "trainval_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のデータでは, \"Date\"と\"Time\", \"SunRise_Time\", \"SunSet_Time\"の4つの説明変数がオブジェクト型となっており, 何等かの処理を施すことで学習に使用できるように変換する必要がある  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは, \"Date\"と\"Time\"だが, これらの説明変数は\"UNIX_Time\"という説明変数と役割が被っているため, 正直必要がない  \n",
    "\"UNIX_Time\"はint型であり, 都合がよいため, 今回はこの説明変数を残すことにする  \n",
    "また, \"UNIX_Time\"をpandasに用意されているdatetime64型という時系列データを扱う上で処理で役に立つ型へ変換し, インデックスに指定する  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNIX_Timeをdatetime型に変換し, indexに指定\n",
    "hawaii = timezone('Pacific/Honolulu')\n",
    "trainval_data.index = pd.to_datetime(trainval_data['UNIX_Time'], unit='s')\n",
    "trainval_data.drop(['UNIX_Time','Date', 'Time'], axis=1, inplace=True)\n",
    "trainval_data.index = trainval_data.index.tz_localize(pytz.utc).tz_convert(hawaii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に, \"SunRise_Time\"と\"SunSet_Time\"だが, \"UNIX_Time\"と同様にDatetime64型に変換しておくことで, 時系列データ処理が行いやすい形に変換しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object型のカラムの変換\n",
    "trainval_data['SunRise_Time'] = pd.to_datetime(trainval_data['SunRise_Time'], format='%H:%M:%S')\n",
    "trainval_data['SunSet_Time'] = pd.to_datetime(trainval_data['SunSet_Time'], format='%H:%M:%S')\n",
    "trainval_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に, データに存在する欠損値を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#欠損値の確認\n",
    "trainval_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のデータではどの変数にも欠損値が存在していないことが確認できたため, 欠損値を処理する手間が省けた  \n",
    "\n",
    "欠損値の扱いには色々ある．以下は例\n",
    "- 時間的に前後のデータから補間(欠損規模に依存)\n",
    "- 他の変数を参考に似ているデータから計算(例: 1年前の同日の値を使用)\n",
    "- そもそも欠損値の時点データを使わない(無難)\n",
    "\n",
    "ただし，欠損値の処理はテストデータには行わない  \n",
    "補間した値を使って『学習』する分のは自由だが，補間した値を使って『予測』するのは自分で作ったデータを予測していることになるため，あまり適切でない  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量エンジニアリング(FE:Feature Engineering)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習の『性能向上を目的とした』前処理を行う（ズルはダメ）  \n",
    "ここでの処理は使用する学習器やそもそもの目的によって大きく変わる  \n",
    "無限に考えられるのでここでは適当にやってみる  \n",
    "だけど最近多く用いられる深層学習はそもそも特徴量エンジニアリングから学習までを行うものであるため不要とも考えられる"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不要カラムの削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "説明変数は多いほど良いというものでもない(多重共線性の誘発)し, 少なければ良いというものでもない(モデルの表現力低下)  \n",
    "そのため, 最適な説明変数を模索していく必要がある  \n",
    "まずは, 学習精度向上にほとんど意味の無いと思う(むしろ無い方が精度が高くなることもある)説明変数を削除してみる  \n",
    "学習時の特徴量重要度等を出力してみて, その結果から削除する流れの方が自然だが, 精度ばかり気にして, 残った説明変数が合理性に欠けてしまい, 妥当な学習モデルになっていない可能性もあることに注意  \n",
    "\n",
    "例) アイスクリームの売り上げを予測するモデルの説明変数に「季節」や「気温」等を削除し, 「水難事故の件数」にした方が精度が上がったとして, それは妥当だと言えるか？(疑似相関)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は, とりあえずデモとして\"Wind_Direction\"という説明変数を削除してみる。(本当は重要な説明変数かも？)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不要カラムの削除\n",
    "trainval_data.drop('Wind_Direction', axis=1, inplace=True)\n",
    "trainval_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 記述統計量の追加"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大，最小，平均，分散など記述統計量を特徴量として追加する  \n",
    "集約範囲は過去1日，1週間，1か月などいろいろ  \n",
    "経験的にはあまり効果的でないことが多いが，とりあえず色んな変数の記述統計量を入れて学習して，結果から取捨選択する手もある  \n",
    "理論上は, 外れ値等に強くなりロバストな学習が実現したり, 目的変数にフィットする説明変数に化ける可能性もある  \n",
    "また，記述統計量ではないが積算値や階差値も利用可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は, \"Temprature\"という説明変数の1次階差(一つ前時点との差)を説明変数として加えてみる  \n",
    "前時点を考慮した予測になってくれればいいなくらいの効果を淡く期待している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempratureの1次階差を追加\n",
    "trainval_data['Temprature_diff'] = trainval_data['Temprature'] - trainval_data['Temprature'].shift(1)\n",
    "trainval_data.dropna(how='any',axis=0, inplace=True)\n",
    "trainval_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 時間情報を追加"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "時間情報が大きく影響する場合有効  \n",
    "ただし，時間という数字はあくまで人間が作り出したものと考えるとあまり適切ではない気もする  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は, Datetime64型の\"SunRise_Time\"と\"SunSet_Time\"という説明変数があったため, 組み合わせて一つの説明変数にしてみようと思う  \n",
    "発想としては, 日の出から日の入りまでの時間があるなら, 「日が出ている時間」という説明変数を生み出すことができるのではないかという経緯である  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ということで, \"SunSet_Time\"と\"SunRise_Time\"の差を\"Day_Length\"という名前の説明変数として追加し, 多重共線性を回避するため, \"SunRise_Time\"と\"SunSet_Time\"を削除する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data['Day_Length'] = trainval_data['SunSet_Time'].dt.hour*60*60 + trainval_data['SunSet_Time'].dt.minute*60 + trainval_data['SunSet_Time'].dt.second \\\n",
    "                           - trainval_data['SunRise_Time'].dt.hour*60*60 - trainval_data['SunRise_Time'].dt.minute*60 - trainval_data['SunRise_Time'].dt.second\n",
    "trainval_data.drop(['SunRise_Time', 'SunSet_Time'], axis=1, inplace=True)\n",
    "trainval_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tsfresh事件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去年の情報科学演習(現在のB4がB3だった時)の時系列パートで起こった事件の一つを以下で紹介します。読み飛ばしてもらっても構いません  \n",
    "\n",
    "事件の始まりは, 「\"tsfresh\"という時系列特徴量を大量に自動生成してくれるライブラリもあるので使ってみるといいかも」という先輩の意見からだった  \n",
    "そんな便利なライブラリがあるなら使うしかない！と思った当時B3のR.O君はtsfreshをインストールして実際に使用した結果を進捗報告で紹介した(以下, 当時の会話内容)  \n",
    "\n",
    "R.O君「使ってみたが, 結論:tsfreshは使えないことが分かった」↓当時の発表スライド↓  \n",
    "\n",
    "<img src='./image/image1.jpg' width=600>\n",
    "\n",
    "峰野先生「でもさぁ～！, 作った人もさぁ～！何かに使えるから作ったと思うんだよね～。すぐに決めつけちゃうのは研究者として良くないと思うな！」  \n",
    "\n",
    "R.O君「はぁ、、」  \n",
    "\n",
    "R.O君はその後しばらく, 峰野先生から, 使えないことが分かったと決めつけるキャラとしてイジられることとなった  \n",
    "これ以降R.O君の口からtsfreshという言葉を聞くことは無くなったのである、、  \n",
    "\n",
    "tsfreshが本当は使える可能性もまだ何%か残っているかもしれないので, 時間があれば試してみてほしい"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適当に特徴量エンジニアリング（FE）をやってみた  \n",
    "FEは前の章でやったデータ前処理と異なり，『機械学習にとって都合の良い特徴量を生成すること』が目的になるため，意味が分からないけど優秀な特徴量を生成してみてもいい  \n",
    "ただし，ここでの処理も一応データ提供者側に妥当かどうか確認を行う方がいいと思う  \n",
    "また，単純に精度が高いモデルを作るのが目的なら良いものの，その特徴量自体が目的に近い存在ならばよく考えてFEする必要があるのは当然"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ探索分析(EDA:Explanatory Data Analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どのようなデータを使うかを確認する  \n",
    "最初はとりあえずいくつか可視化してみてデータの特徴，傾向をつかむ  \n",
    "機械学習を使用するということはまだ置いといて，ドメイン知識や分析結果を用いてデータの前処理行う"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 折れ線グラフ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "折れ線グラフをプロットする  \n",
    "注意点としては離散値はそのままでは数値型でなくプロットできない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10')\n",
    "plt.figure(figsize=[13,10])\n",
    "for i, c in enumerate(trainval_data.columns):\n",
    "    plt.subplot(6,2,i+1)\n",
    "    plt.plot(trainval_data.index, trainval_data[c], c=cmap(i%10), linewidth=1)\n",
    "    plt.title(c)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒストグラム"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "箱ひげ図よりもより細かく分布を把握できる  \n",
    "ビンの数によって凹凸具合が割と簡単に変わりやすいので注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10')\n",
    "plt.figure(figsize=[13,10])\n",
    "for i, c in enumerate(trainval_data.columns):\n",
    "    plt.subplot(6,2,i+1)\n",
    "    sns.histplot(data=trainval_data, x=c, bins=30, color=cmap(i%10), kde=True)\n",
    "    plt.title(c)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒートマップ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame.corr()で各カラム間の相関係数を計算してくれる（数値型以外は無視）  \n",
    "seabornのheatmapに入れるだけで分かりやすく可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = trainval_data.corr()\n",
    "plt.figure(figsize=[10,8])\n",
    "sns.heatmap(corr, cmap=sns.color_palette('coolwarm', 10), annot=True, fmt='.2f', vmin = -1, vmax = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでの様々な工程で加工されたデータを新たにprocessed_dataという名称でcsvとして保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data.to_csv('./data/processed_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残りは学習モデルを使って予測を行っていく  \n",
    "モデルの学習はmodel.ipynbで行う"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
